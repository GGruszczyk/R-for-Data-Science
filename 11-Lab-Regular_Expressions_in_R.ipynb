{"cells":[{"cell_type":"markdown","metadata":{},"source":["\u003cimg src=\"http://cognitiveclass.ai/wp-content/uploads/2017/11/cc-logo-square.png\" width=\"150\"\u003e\n","\n","\u003ch1 align=center\u003eREGULAR EXPRESSIONS IN R\u003c/h1\u003e \n","\n"]},{"cell_type":"markdown","metadata":{},"source":["In this notebook, we will study some simple Regular Expression terms and apply them with R functions.\n"]},{"cell_type":"markdown","metadata":{},"source":["### Table of contents\n","\n","- \u003cp\u003e\u003ca href=\"#Loading-in-Data\"\u003eLoading in Data\u003c/a\u003e\u003c/p\u003e\n","- \u003cp\u003e\u003ca href=\"#Regular-Expressions\"\u003eRegular Expressions\u003c/a\u003e\u003c/p\u003e\n","- \u003cp\u003e\u003ca href=\"#Regular-Expression-in-R\"\u003eRegular Expression in R\u003c/a\u003e\u003c/p\u003e\n","\u003cp\u003e\u003c/p\u003e\n","\u003chr\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["\u003ca id=\"ref9001\"\u003e\u003c/a\u003e\n","# Loading in Data\n"]},{"cell_type":"markdown","metadata":{},"source":["Let's load in a small list of emails to perform some data analysis and take a look at it.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":["email_df \u003c- read.csv(\"https://ibm.box.com/shared/static/cbim8daa5vjf5rf4rlz11330lvqbu7rk.csv\")\n","email_df"]},{"cell_type":"markdown","metadata":{},"source":["So our simple dataset contains a list of names and a list of their corresponding emails. Let's say we want to simply count the frequency of email domains. But several problems arise before we can even attempt this. If we attempt to simply count the email column, we won't end up with what we want since every email is unique. And if we split the string at the '@', we still won't have what we want since even emails with the same domains might have different regional extensions. So how can we easily extract the necessary data in a quick and easy way?\n"]},{"cell_type":"markdown","metadata":{},"source":["\u003ca id=\"funyarinpa\"\u003e\u003c/a\u003e\n","# Regular Expressions\n"]},{"cell_type":"markdown","metadata":{},"source":["Regular Expressions are generic expressions that are used to match patterns in strings and text. A way we can exemplify this is with a simple expression that can match with an email string. But before we write it, let's look at how an email is structured:\n","\n","\u003ccode\u003e$test@testing.com$\u003c/code\u003e\n","\n","So, an email is composed by a string followed by an '@' symbol followed by another string. In R regular expressions, we can express this as:\n","\n","\u003ccode\u003e$.+@.+$\u003c/code\u003e\n","\n","Where:\n","* The '.' symbol matches with any character.\n","* The '+' symbol repeats the previous symbol one or more times. So, '.+' will match with any string.\n","* The '@' symbol only matches with the '@' character.\n","\n","Now, for our problem, which is extracting the domain from an email excluding the regional url code, we need an expression that specifically matches with what we want:\n","\n","\u003ccode\u003e$@.+\\\\\\\\.$\u003c/code\u003e\n","\n","Where the \u003ccode\u003e'\\\\\\\\.'\u003c/code\u003e symbol specifically matches with the '.' character.\n"]},{"cell_type":"markdown","metadata":{},"source":["\u003ca id=\"imyourpoutine\"\u003e\u003c/a\u003e\n","# Regular Expressions in R\n"]},{"cell_type":"markdown","metadata":{},"source":["Now let's look at some R functions that work with R functions.\n","\n","The grep function below takes in a Regular Expression and a list of strings to search through and returns the positions of where they appear in the list.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"scrolled":true},"outputs":[],"source":["grep(\"@.+\",  c(\"test@testing.com\" , \"not an email\", \"test2@testing.com\"))"]},{"cell_type":"markdown","metadata":{},"source":["Grep also has an extra parameter called 'value' that changes the output to display the strings instead of the list positions. \n"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":["grep(\"@.+\",  c(\"test@testing.com\", \"not an email\", \"test2@testing.com\"), value=TRUE)"]},{"cell_type":"markdown","metadata":{},"source":["The next function, 'gsub', is a substitution function. It takes in a Regular Expression, the string you want to swap in with the matches and a list of strings you want to perform the swap with. The code cell below updates valid emails with a new domain:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":["gsub(\"@.+\", \"@newdomain.com\", c(\"test@testing.com\", \"not an email\", \"test2@testing.com\"))"]},{"cell_type":"markdown","metadata":{},"source":["The functions below, 'regexpr' and 'regmatches', work in conjunction to extract the matches found by a regular expression specified in 'regexpr'.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":["matches \u003c- regexpr(\"@.*\", c(\"test@testing.com\", \"not an email\", \"test2@testing.com\"))\n","regmatches(c(\"test@testing.com\", \"not an email\", \"test2@testing.com\"), matches)"]},{"cell_type":"markdown","metadata":{},"source":["This function is actually perfect for our problem since we simply need to extract the specific information we want. So let's use it with the Regular Expression we defined above and store the extracted strings in a new column in our dataframe.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":["matches \u003c- regexpr(\"@.*\\\\.\", email_df[,'Email'])\n","email_df[,'Domain'] = regmatches(email_df[,'Email'], matches)"]},{"cell_type":"markdown","metadata":{},"source":["And this is the resulting dataframe:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":["email_df"]},{"cell_type":"markdown","metadata":{},"source":["Now we can finally construct the frequency table for the domains in our dataframe!\n"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":["table(email_df[,'Domain'])"]},{"cell_type":"markdown","metadata":{},"source":["\u003chr\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Scaling R with big data\n","\n","As you learn more about R, if you are interested in exploring platforms that can help you run analyses at scale, you might want to sign up for a free account on [IBM Watson Studio](http://cocl.us/dsx_rp0101en), which allows you to run analyses in R with two Spark executors for free.\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\u003chr\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Author: Gabriel Sousa\n"]},{"cell_type":"markdown","metadata":{},"source":["\u003chr\u003e\n","\n","\n","Copyright \u0026copy; [IBM Cognitive Class](https://cognitiveclass.ai/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkRP0101ENSkillsNetwork933-2023-01-01). This notebook and its source code are released under the terms of the [MIT License](https://cognitiveclass.ai/mit-license/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkRP0101ENSkillsNetwork933-2023-01-01).\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":""}},"nbformat":4,"nbformat_minor":2}